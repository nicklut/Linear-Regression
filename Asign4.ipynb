{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 6390: Assignment 4\n",
    "## Due October 14th\n",
    "### By: Nicholas Lutrzykowski \n",
    "The goal of this assignment is to build a regression model to predict the number of shares of a news article. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements \n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and setup data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: 30\n",
      "Number of points: 39644\n"
     ]
    }
   ],
   "source": [
    "data_orig = np.genfromtxt('OnlineNewsPopularity.csv', delimiter=',')\n",
    "\n",
    "data = np.concatenate((data_orig[1:,2:4], data_orig[1:, 7:13], data_orig[1:, 39:61]), axis=1)\n",
    "\n",
    "num_points = data.shape[0]\n",
    "num_attributes = data.shape[1]\n",
    "print(\"Number of attributes:\", num_attributes)\n",
    "print(\"Number of points:\", num_points)\n",
    "\n",
    "# Read in the titles \n",
    "file = open('OnlineNewsPopularity.csv')\n",
    "csvreader = csv.reader(file)\n",
    "header = [] \n",
    "header = next(csvreader)\n",
    "header = header[2:13] + header[39:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (31715, 30)\n",
      "Validation shape: (3964, 30)\n",
      "Test shape: (3965, 30)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(data)\n",
    "np.random.shuffle(data)\n",
    "num_training, num_validation = 31715, 3964+31715\n",
    "\n",
    "\n",
    "training = data[:num_training, :]\n",
    "validation = data[num_training:num_validation, :]\n",
    "test = data[num_validation:, :]\n",
    "training_target, validation_target, test_target = training[:, -1], validation[:, -1], test[:, -1]\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(training[:,:-1])\n",
    "training = np.concatenate((np.ones((num_training,1), dtype=float),scaler.transform(training[:,:-1])), axis=1)\n",
    "\n",
    "validation = np.concatenate((np.ones((num_validation-num_training,1), dtype=float), scaler.transform(validation[:,:-1])), axis=1)\n",
    "test = np.concatenate((np.ones((num_points-num_validation,1), dtype=float), scaler.transform(test[:,:-1])), axis=1)\n",
    "\n",
    "print(\"Training shape:\", training.shape)\n",
    "print(\"Validation shape:\", validation.shape)\n",
    "print(\"Test shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Linear Regression via QR Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_Factorization(data): \n",
    "    Q = np.ones(data.shape, dtype=float)\n",
    "    R = np.zeros((data.shape[1], data.shape[1]), dtype=float)\n",
    "    R[0,0] = 1\n",
    "    \n",
    "    for i in range(1, Q.shape[1]):\n",
    "        Q[:, i] = data[:, i]\n",
    "        R[i, i] = 1\n",
    "        for j in range(i): \n",
    "            pji = np.dot(data[:,i].T, Q[:,j])/np.dot(Q[:,j].T, Q[:,j])\n",
    "            R[j, i] = pji \n",
    "            Q[:,i] -= np.dot(pji, Q[:,j])\n",
    "\n",
    "    return Q, R\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_sub(R, ortho_q_y):\n",
    "    w = np.zeros((R.shape[0],))\n",
    "    \n",
    "    for i in range(R.shape[0]-1, -1, -1):\n",
    "        w[i] = ortho_q_y[i]\n",
    "        \n",
    "        for j in range(i+1, R.shape[0]):\n",
    "            w[i] -= w[j]*R[i,j]\n",
    "        \n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_regression(training, Y):\n",
    "    Q, R = QR_Factorization(training)\n",
    "\n",
    "    ortho = np.matmul(Q.T, Q)\n",
    "    ortho = 1/ortho\n",
    "    ortho = np.where(ortho < 1e10, ortho, 0)\n",
    "    ortho = np.where(ortho > -1e10, ortho, 0)\n",
    "    \n",
    "    ortho_q_y = np.matmul(np.matmul(ortho, Q.T), Y)\n",
    "    \n",
    "    w = back_sub(R, ortho_q_y)\n",
    "    \n",
    "    return w\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_results(w, test, Y): \n",
    "    Y_hat = np.matmul(test, w)\n",
    "    \n",
    "    epsilon = Y-Y_hat\n",
    "    SSE = np.dot(epsilon.T, epsilon)\n",
    "    TSS = np.sum((Y-np.mean(Y))**2)\n",
    "    \n",
    "    R2 = (TSS-SSE)/TSS\n",
    "    \n",
    "    return SSE, TSS, R2\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE is: 342677374158.571\n",
      "TSS is: 350624971631.2273\n",
      "R-squared is: 0.022666946497510915\n"
     ]
    }
   ],
   "source": [
    "w = multiple_regression(training, training_target)\n",
    "\n",
    "SSE, TSS, R2 = find_results(w, test, test_target)\n",
    "\n",
    "print(\"SSE is:\", SSE)\n",
    "print(\"TSS is:\", TSS)\n",
    "print(\"R-squared is:\", R2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why the above R-squared value is such a large negative number, I had a very small negative number prior to implementing part 2. I do not have time to debug why this is occuring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_points = np.random.permutation(np.arange(training.shape[0]))\n",
    "alphas = np.array([ 0, 1, 10, 100, 1000, 10000])\n",
    "w_results = [] \n",
    "epsilon = 0.0001\n",
    "eta = 1e-6\n",
    "\n",
    "for alpha in alphas:\n",
    "    dif = epsilon*2\n",
    "    wprev = np.random.rand(num_attributes,)\n",
    "  \n",
    "    while dif > epsilon: \n",
    "        delta_w = -np.matmul(training.T, training_target) + np.matmul(np.matmul(training.T, training), wprev) + (alpha*wprev)\n",
    "        w = wprev - (eta*delta_w)\n",
    "        \n",
    "        rand_points = np.random.permutation(rand_points)\n",
    "        dif = np.sum((w - wprev)**2)\n",
    "        wprev = w \n",
    "    \n",
    "    w_results.append(wprev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value is: 1000\n",
      "The weights are:\n",
      "[ 3.30292493e+03  1.08161584e+02  3.29107835e+01  4.35977519e+02\n",
      " -2.41736851e+02  1.63725109e+02  7.28187177e+01 -2.72636141e+02\n",
      "  2.06026354e+02  8.28211705e+01 -1.69418621e+02 -4.44782174e+02\n",
      "  5.03719550e+02 -2.48779334e+01  4.90667579e+02 -2.21722548e+01\n",
      " -1.40438608e+02  2.24494169e+01 -1.93411524e+02 -1.19207815e+02\n",
      "  1.23813097e+00 -8.67214259e+01 -4.26607540e+01 -1.83463755e+02\n",
      "  4.05839051e+01 -1.09235671e+02 -1.03649839e+01  4.34829415e+01\n",
      "  5.96544530e+01  1.47237354e+02]\n",
      "The R2 on the test data is: 0.024155528598761678\n"
     ]
    }
   ],
   "source": [
    "min_SSE = np.Inf\n",
    "opt = np.Inf\n",
    "\n",
    "for i in range(len(w_results)): \n",
    "    SSE, TSS, R2 = find_results(w_results[i], validation, validation_target)\n",
    "    \n",
    "    if SSE < min_SSE: \n",
    "        min_SSE = SSE\n",
    "        opt = i\n",
    "\n",
    "print(\"The best alpha value is:\", alphas[opt])\n",
    "print(\"The weights are:\")\n",
    "print(w_results[opt])\n",
    "\n",
    "SSE, TSS, R2 = find_results(w_results[opt], test, test_target)\n",
    "\n",
    "print(\"The R2 on the test data is:\", R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99ef57a3e309b3ccef27bfdc21155d00f14e44d33227cb907457916f15963b11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
